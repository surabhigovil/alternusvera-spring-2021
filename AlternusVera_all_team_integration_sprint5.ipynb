{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AlternusVera_all_team_integration_sprint5.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"e77d84663ff34349b689c225fcbf34be":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_43a247e2da98422cb47f93740d996f6e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a167a417e3ae4cb18b195cacebb2079a","IPY_MODEL_6769af88747747b7b46beb5a800c8dba"]}},"43a247e2da98422cb47f93740d996f6e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a167a417e3ae4cb18b195cacebb2079a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_61c3421741764ee6b91678b3f3ddac1e","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":244715968,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":244715968,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0c8b47a349cd472a9f22aba320f9d654"}},"6769af88747747b7b46beb5a800c8dba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f30ee3b59e1e4f258457e46a9a073c03","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 245M/245M [00:13&lt;00:00, 17.7MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4fefbcfd9cff4559b8a5bbb350d75fc6"}},"61c3421741764ee6b91678b3f3ddac1e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0c8b47a349cd472a9f22aba320f9d654":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f30ee3b59e1e4f258457e46a9a073c03":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4fefbcfd9cff4559b8a5bbb350d75fc6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"1ozZMQ-jqp0j"},"source":["# CMPE 257 - MLSprings 2021 Cohort\n","## Objective: Detect fake news in political datasets using factors\n","\n","## Factors by Team\n","## Team Equality - Abhishek Bais, Haley Feng, Jimmy Liang, Shannon Phu\n","### Abhishek - Misleading Intentions\n","#### Microfactors:  \n","Sentiment Analysis  \n","Sensationalism  \n","Click Bait \n","\n","Datasets:\n","1. [Politifact](drive.google.com/file/d/1LUTnGJ1c8WDwcEmed85GhfoEUm2sJFzN/view)  \n","2. [Amalgamated dataset from varied newsAPI feed](https://docs.google.com/spreadsheets/d/1jJflezhjlTPRoVHvj7UvQwllssq66zhZNPz7GI_Zwhc/edit#gid=22382224)  \n","3. [Sensational words corpus](https://drive.google.com/file/d/1JIes9QhZw7EUt59EBDUgrdFMokoT1W8u/view)  \n","\n","### Shannon - Stance Detection\n","#### Microfactors:  \n","Sentiment Analysis  \n","Subjectivity Score  \n","BERT Embeddings  \n","\n","Datasets:\n","1. [Fake News Challenge](https://www.kaggle.com/c/fakenewskdd2020)  \n","2. [Politifact](drive.google.com/file/d/1LUTnGJ1c8WDwcEmed85GhfoEUm2sJFzN/view)  \n","3. [Sentiment words corpus](https://drive.google.com/file/d/1JIes9QhZw7EUt59EBDUgrdFMokoT1W8u/view)  \n","\n","### Haley - Political Bias\n","#### Microfactors: \n","Sentiment Analysis  \n","Party Affiliation  \n","Vocab Selection Bias  \n","1. Politifact\n","2. [GoogleNews API](https://docs.google.com/spreadsheets/d/1Uu-266Q0ab88fnnjtrZ8MMMV8KGNzGoiGKXbBssza2s/edit?usp=sharing)\n","3. [Ideological Book Corpus](https://people.cs.umass.edu/~miyyer/ibc/index.html) / [Kaggle Tweets](https://docs.google.com/spreadsheets/d/14KRtIdMqbp1Tnd7AraR-ROtPDTSQgc--hMmm0L7baDc/edit?usp=sharing)\n","\n","### Jimmy - Naive Realism\n","#### Microfactors:  \n","Topic Centrality  \n","Polarization  \n","Source Centrality  \n","\n","## Team DataCorps - Yuxing Wang, Arun Talkad, Mayuri Lalwani\n","\n","### Yuxing - Psychology Utilities\n","#### Microfactors:\n","Group confirmation<br />\n","Opinion leader<br />\n","Sentiment<br />\n","Datasets:\n","1. Politifact\n","2. Twitter API\n","3. News API\n","\n","### Mayuri - Intent\n","#### Microfactors:\n","Utterance<br />\n","Speech<br />\n","Sentiment<br />\n","Datasets:\n","1. politifact\n","2. twitter\n","3. newsapi\n","\n","### Arun - Source Reputation, Source Reliability\n","#### Microfactors:\n","Provenance Analysis <br />\n","News Subjectivity   <br />             \n","News Credibility  <br />              \n","News Veracity Detection <br />\n","Datasets:\n","1. Politifact\n","2. Twitter API\n","3. News API <br />\n","\n","## Team Sparrow \n","### Princy\n","#### Microfactors\n","Text similarity<br/>\n","Sentiment Polarity <br/>\n","Datasets:\n","1. [Stance Dataset](http://www.fakenewschallenge.org)\n","2. [ISOT Fake News Dataset\n","](https://www.uvic.ca/engineering/ece/isot/datasets/fake-news/index.php)\n","3. [Kaggle](https://www.kaggle.com/c/fake-news/)\n","\n","## Team Amalgam\n","### Surabhi: Credibility\n","#### Microfactors\n","Author Experise<br />\n","Content Credibility<br />\n","Text Readability<br />\n","Datasets Used: \n","1. Scraped Data from Politifact website \n","2. Scraped news article from web\n","\n","### Arpitha:  Style based approaches\n","#### Microfactors\n","Hyperpartisan<br />\n","Yellow Journalism<br />\n","Deception/Lying in text<br />\n","Datasets Used: \n","1. Kaggle fake news dataset: https://www.kaggle.com/surekharamireddy/fake-news-detection\n","2. SemEval Hyperpartisan News Detection task dataset: https://pan.webis.de/semeval19/semeval19-web/\n","\n","### Gayathri: Authenticity\n","#### Microfactors\n","Flesch Reading Ease Score<br />\n","Polarity score<br />\n","Subjectivity Score<br />\n","Datasets Used: \n","1. Scraped Data from Politifact website\n","\n","\n","\n","## Team Underdog \n","### Jocelyn \n","### Source Reputation\n","#### Microfactors\n","Source Ratings Score \n","Reputation Score \n","Sentence Similarity\n","### Datasets used:\n","1. Scraped Data from Politifact and FoxNews Website\n","\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7C4abpQqjAj5","executionInfo":{"status":"ok","timestamp":1620488408455,"user_tz":420,"elapsed":10405,"user":{"displayName":"Yuxing Wang","photoUrl":"","userId":"03421613890437063978"}},"outputId":"901226a1-3c55-46fe-e463-8a3bde5c769b"},"source":["!pip install sentence-transformers\n","!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting sentence-transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c4/87/49dc49e13ac107ce912c2f3f3fd92252c6d4221e88d1e6c16747044a11d8/sentence-transformers-1.1.0.tar.gz (78kB)\n","\u001b[K     |████████████████████████████████| 81kB 7.8MB/s \n","\u001b[?25hCollecting transformers<5.0.0,>=3.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n","\u001b[K     |████████████████████████████████| 2.1MB 24.2MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.41.1)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.8.1+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 52.3MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (20.9)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.10.1)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 47.1MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2.23.0)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 54.4MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.12)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.4.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers) (7.1.2)\n","Building wheels for collected packages: sentence-transformers\n","  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sentence-transformers: filename=sentence_transformers-1.1.0-cp37-none-any.whl size=119615 sha256=a7616dddba616e07150606153164ed5259b09669e2d87983d61c8e60bc0ee266\n","  Stored in directory: /root/.cache/pip/wheels/84/cb/21/1066bff3027215c760ca14a198f698bca8fccb92e33e2327eb\n","Successfully built sentence-transformers\n","Installing collected packages: tokenizers, sacremoses, transformers, sentencepiece, sentence-transformers\n","Successfully installed sacremoses-0.0.45 sentence-transformers-1.1.0 sentencepiece-0.1.95 tokenizers-0.10.2 transformers-4.5.1\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Wt6Ge7dNq29P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620488415334,"user_tz":420,"elapsed":17277,"user":{"displayName":"Yuxing Wang","photoUrl":"","userId":"03421613890437063978"}},"outputId":"99c3dea4-5a32-4db7-dda5-71f217788c6e"},"source":["# Import standard libraries\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from io import BytesIO\n","import requests\n","import pickle\n","import nltk\n","from transformers import pipeline\n","nltk.download('punkt')\n","from nltk.sentiment.vader import SentimentIntensityAnalyzer\n","nltk.download('vader_lexicon')\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n","  warnings.warn(\"The twython library has not been installed. \"\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"q6JXxaedfOj7"},"source":["!pip install -U -q pyDrive"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FWqJQotGeV6b"},"source":["# Import packages for google drive, auth\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","gdrive = GoogleDrive(gauth)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tvzcys0ueBkd"},"source":["from sklearn.preprocessing import PolynomialFeatures\n","from textblob import TextBlob\n","from sentence_transformers import SentenceTransformer"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"noSA0zB6nzwJ"},"source":["# 1.0. Read in streaming news headlines\n","\n","a. Streaming news headlines are from https://newsapi.org/  \n","c. Streaming news headlines are from CNN, Brietbart News and Fox News 2021/4/25 - 2021/4/26"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":742},"id":"UEdR7Valn_H2","executionInfo":{"status":"ok","timestamp":1620488435495,"user_tz":420,"elapsed":37429,"user":{"displayName":"Yuxing Wang","photoUrl":"","userId":"03421613890437063978"}},"outputId":"a2102455-384b-44fa-9e55-582a9237089e"},"source":["r = requests.get('https://docs.google.com/spreadsheets/d/e/2PACX-1vQoXVHhfQlxAlQ8b3eHot7dDhXmCYM9iYC7i0mZMMpzwejhvCjMeEEHPTRhI7KCqOkRbmHBfsxKp0gw/pub?gid=1486725861&single=true&output=tsv')\n","data = r.content\n","df_test_headlines = pd.read_csv(BytesIO(data), sep='\\t')\n","df_test_headlines"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>text</th>\n","      <th>body</th>\n","      <th>source</th>\n","      <th>preprocessed_statement_text</th>\n","      <th>preprocessed_body</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2021-04-26T23:59:00Z</td>\n","      <td>India is spiraling deeper into Covid-19 crisis...</td>\n","      <td>India is experiencing the world's worst Covid-...</td>\n","      <td>CNN</td>\n","      <td>india spiral deeper covid crisi need know</td>\n","      <td>india experienc world worst covid outbreak rec...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2021-04-26T23:52:26Z</td>\n","      <td>New York to lose House seat -- and an Electora...</td>\n","      <td>New York state came just 89 residents short of...</td>\n","      <td>CNN</td>\n","      <td>new york lose hous seat elector colleg vote fa...</td>\n","      <td>new york state came resid short maintain congr...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2021-04-26T23:29:09Z</td>\n","      <td>Trump's effort to overturn loss becomes 2022 G...</td>\n","      <td>Former North Carolina Gov. Pat McCrory acknowl...</td>\n","      <td>CNN</td>\n","      <td>trump effort overturn loss becom gop litmus te...</td>\n","      <td>former north carolina gov pat mccrori acknowle...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2021-04-26T23:27:31Z</td>\n","      <td>Fox News host admits his show was wrong about ...</td>\n","      <td>A Fox News anchor admitted on air on Monday th...</td>\n","      <td>CNN</td>\n","      <td>fox news host admit show wrong biden limit red...</td>\n","      <td>fox news anchor admit air monday show inaccur ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2021-04-26T22:40:13Z</td>\n","      <td>The Chauvin trial produced a new liberal icon</td>\n","      <td>The conviction last week of former Minneapolis...</td>\n","      <td>CNN</td>\n","      <td>chauvin trial produc new liber icon</td>\n","      <td>convict last week former minneapoli polic offi...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>294</th>\n","      <td>2021-04-26T16:57:43Z</td>\n","      <td>Disney World is hiring in preparation for capa...</td>\n","      <td>Things are apparently getting busier at Disney...</td>\n","      <td>Fox News</td>\n","      <td>disney world hire prepar capac increas report</td>\n","      <td>thing appar get busier disney world</td>\n","    </tr>\n","    <tr>\n","      <th>295</th>\n","      <td>2021-04-26T16:53:12Z</td>\n","      <td>New York Times 'buried' bombshell that John Ke...</td>\n","      <td>The New York Times is taking criticism for \"bu...</td>\n","      <td>Fox News</td>\n","      <td>new york time buri bombshel john kerri told ir...</td>\n","      <td>new york time take critic buri report former s...</td>\n","    </tr>\n","    <tr>\n","      <th>296</th>\n","      <td>2021-04-26T16:39:50Z</td>\n","      <td>Arizona's Flag Fire balloons in size, promptin...</td>\n","      <td>The Flag Fire in Arizona has swelled to a dang...</td>\n","      <td>Fox News</td>\n","      <td>arizona flag fire balloon size prompt evacu</td>\n","      <td>flag fire arizona swell danger level prompt of...</td>\n","    </tr>\n","    <tr>\n","      <th>297</th>\n","      <td>2021-04-26T16:36:44Z</td>\n","      <td>Used pickup prices are skyrocketing amid new v...</td>\n","      <td>A shortage of new vehicles has led to steep in...</td>\n","      <td>Fox News</td>\n","      <td>use pickup price skyrocket amid new vehicl sho...</td>\n","      <td>shortag new vehicl led steep increas price use...</td>\n","    </tr>\n","    <tr>\n","      <th>298</th>\n","      <td>2021-04-26T16:31:52Z</td>\n","      <td>Dubai sheikh still chasing elusive Kentucky De...</td>\n","      <td>Winning major horse races around the world is ...</td>\n","      <td>Fox News</td>\n","      <td>dubai sheikh still chase elus kentucki derbi v...</td>\n","      <td>win major hors race around world lifeblood god...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>299 rows × 6 columns</p>\n","</div>"],"text/plain":["                     date  ...                                  preprocessed_body\n","0    2021-04-26T23:59:00Z  ...  india experienc world worst covid outbreak rec...\n","1    2021-04-26T23:52:26Z  ...  new york state came resid short maintain congr...\n","2    2021-04-26T23:29:09Z  ...  former north carolina gov pat mccrori acknowle...\n","3    2021-04-26T23:27:31Z  ...  fox news anchor admit air monday show inaccur ...\n","4    2021-04-26T22:40:13Z  ...  convict last week former minneapoli polic offi...\n","..                    ...  ...                                                ...\n","294  2021-04-26T16:57:43Z  ...                thing appar get busier disney world\n","295  2021-04-26T16:53:12Z  ...  new york time take critic buri report former s...\n","296  2021-04-26T16:39:50Z  ...  flag fire arizona swell danger level prompt of...\n","297  2021-04-26T16:36:44Z  ...  shortag new vehicl led steep increas price use...\n","298  2021-04-26T16:31:52Z  ...  win major hors race around world lifeblood god...\n","\n","[299 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"I47CwebudtV2"},"source":["# 2.0. Predict news headline is true/ false by ensembling factors"]},{"cell_type":"markdown","metadata":{"id":"timAm5UXdmqP"},"source":["## 2.1. Define a false-o-meter\n","1. Associate weights with each micro-factor proportional to model accuracy\n","2. Probablity news is false is obtained by ensembling micro-factors as follows\n","Define: A [false-o-meter] as s polynomial function f(p) = p0w0 + p1w1 + p2*w2\n","where\n","i. p is predicited probability of a micro-factor\n","ii. w is normalized weight of micro-factors, proportional to accuracy of its prediction\n","\n","3. Labels news as follows based on false-o-meter f(p) reading\n","i. Pants on Fire - if false-o-meter > 0.9\n","ii. Somewhat False - if 0.7 < false-o-meter < 0.9\n","iii. Mostly False - if 0.5 < false-o-meter < 0.7\n","iv. Half True - if 0.3 < false-o-meter < 0.5\n","v. Mostly True - if 0.1 < false-o-meter < 0.3\n","vi. True - if 0.1 < false-o-meter"]},{"cell_type":"markdown","metadata":{"id":"0Tj9YbF3u6u5"},"source":["## 2.2. Define Stance Predictor"]},{"cell_type":"code","metadata":{"id":"AKq470C2grOd"},"source":["def apply_stance_detection_featurization(df_, sentiment_analyzer, headlineCol='Headline', bodyCol='ArticleBody'):\n","  orig_cols = df_.copy().columns\n","  df_['body_sentiment_score'] = df_[bodyCol].apply(lambda text: sentiment_analyzer.polarity_scores(text)['compound'])\n","  df_['body_subjectivity_score'] = df_[bodyCol].apply(lambda text: TextBlob(text).sentiment[1])\n","  df_['title_sentiment_score'] = df_[headlineCol].apply(lambda text: sentiment_analyzer.polarity_scores(text)['compound'])\n","  df_['title_subjectivity_score'] = df_[headlineCol].apply(lambda text: TextBlob(text).sentiment[1])\n","  df_ = df_.reset_index()\n","\n","  feature_names = ['body_sentiment_score', 'body_subjectivity_score', 'title_sentiment_score', 'title_subjectivity_score']\n","  poly = PolynomialFeatures(interaction_only=True)\n","  interaction_features = pd.DataFrame(poly.fit_transform(df_[feature_names].to_numpy()))\n","  interaction_feature_names = poly.get_feature_names(input_features=feature_names)\n","  interaction_features.columns = interaction_feature_names\n","  interaction_features = interaction_features.drop(['1'], axis=1)\n","  interaction_feature_names.remove('1')\n","\n","  headline_sentence_embeddings = pd.DataFrame(np.stack(df_[headlineCol].apply(transformer_model.encode).to_numpy()), columns=['heademb_{}'.format(i) for i in range(768)])\n","  article_sentence_embeddings = pd.DataFrame(np.stack(df_[bodyCol].apply(transformer_model.encode).to_numpy()), columns=['artemb_{}'.format(i) for i in range(768)])\n","\n","  features = pd.concat([df_[orig_cols], interaction_features, headline_sentence_embeddings, article_sentence_embeddings], axis=1)\n","  return features"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VQuyQVdbmd0F","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["e77d84663ff34349b689c225fcbf34be","43a247e2da98422cb47f93740d996f6e","a167a417e3ae4cb18b195cacebb2079a","6769af88747747b7b46beb5a800c8dba","61c3421741764ee6b91678b3f3ddac1e","0c8b47a349cd472a9f22aba320f9d654","f30ee3b59e1e4f258457e46a9a073c03","4fefbcfd9cff4559b8a5bbb350d75fc6"]},"executionInfo":{"status":"ok","timestamp":1620488453083,"user_tz":420,"elapsed":55010,"user":{"displayName":"Yuxing Wang","photoUrl":"","userId":"03421613890437063978"}},"outputId":"44639c9f-5854-4fde-ce94-287783d38e4d"},"source":["file_id = '1DV5hmLvLJWYBviF6ps0nXV5FCu1URXyL'\n","model_filename = 'stance_detection.pkl'\n","downloaded = gdrive.CreateFile({'id': file_id})\n","downloaded.GetContentFile(model_filename)\n","pickle_filepath = '/content/{}'.format(model_filename)\n","stance_detection_model = pickle.load(open(pickle_filepath, 'rb'))\n","\n","sentiment_analyzer = SentimentIntensityAnalyzer()\n","transformer_model = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')\n","\n","def getStancePrediction(X_headline, X_body):\n","  prob = [0, 0, 0]\n","  if X_headline.size == 1:\n","    # prepare data for stance prediction\n","    df = pd.DataFrame([(X_headline.iloc[0], X_body.iloc[0])], columns=['Headline', 'ArticleBody']) \n","    stance_detection_features = apply_stance_detection_featurization(df, sentiment_analyzer, headlineCol='Headline', bodyCol='ArticleBody')\n","    stance_detection_X = stance_detection_features.drop(['Headline', 'ArticleBody'], axis=1).to_numpy()\n","    stance_detection_prediction_score = stance_detection_model.predict_proba(stance_detection_X)[0]\n","    # make a prediction\n","    prob = stance_detection_prediction_score\n","\n","  return prob"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e77d84663ff34349b689c225fcbf34be","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=244715968.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eoz_GwWEuyOK"},"source":["## 2.3. Define Sentiment Predictor"]},{"cell_type":"code","metadata":{"id":"X4qVLO1EdqH2"},"source":["def getSentimentPrediction(X_news):\n","  prob = 0\n","  if X_news.size == 1:\n","    file_id = '1eZ0TycVjHAyaFh8eKDmyLiQ_DN8rOcbI'\n","    model_filename = 'Best_Sentiment_Analysis_Model_Misleading_Intentions.pkl'\n","    downloaded = gdrive.CreateFile({'id': file_id})\n","    downloaded.GetContentFile(model_filename)\n","    pickle_filepath = '/content/{}'.format(model_filename)\n","    best_sentiment_model = pickle.load(open(pickle_filepath, 'rb'))\n","    prob = best_sentiment_model.predict_proba(X_news)[:,1]\n","  return float(prob)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0x8PlEguu1s4"},"source":["## 2.4. Define Sensationalism Predictor"]},{"cell_type":"code","metadata":{"id":"H_MZQd_90cvu"},"source":["def getSensationalismPrediction(X_news):\n","  prob = 0\n","  if X_news.size == 1:\n","    file_id = '1XEYOqUEkI52tW7ZWtIGRq0Qe5dOd2I_S'\n","    model_filename = 'Best_Sensationalism_Analysis_Model_Misleading_Intentions.pkl'\n","    downloaded = gdrive.CreateFile({'id': file_id})\n","    downloaded.GetContentFile(model_filename)\n","    pickle_filepath = '/content/{}'.format(model_filename)\n","    best_sensationalism_model = pickle.load(open(pickle_filepath, 'rb'))\n","    prob = best_sensationalism_model.predict_proba(X_news)[:,1]\n","  return float(prob)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AoC7DQHSvDG6"},"source":["## 2.5. Define ClickBait Predictor"]},{"cell_type":"code","metadata":{"id":"KEEQtnWNd3Ic"},"source":["def getDistilledClickBaitPrediction(X_news):\n","  prob = 0\n","  if X_news.size == 1:\n","    file_id = '1pgSrMJD0m_7Cd1fg1xoZEN2P_CjnpUkb'\n","    model_filename = 'Best_Clickbait_Analysis_Model_Misleading_Intentions.pkl'\n","    downloaded = gdrive.CreateFile({'id': file_id})\n","    downloaded.GetContentFile(model_filename)\n","    pickle_filepath = '/content/{}'.format(model_filename)\n","    best_distilled_clickbait_model = pickle.load(open(pickle_filepath, 'rb'))\n","    prob = best_distilled_clickbait_model.predict_proba(X_news)[:,1]\n","  return float(prob)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v7YJG4qERpqA"},"source":["## 2.6. Define Political Bias\n","\n"]},{"cell_type":"code","metadata":{"id":"KZ_fD6l_R2n9"},"source":["def get_BSF(df): # Balance Sentiment Factor\n","  if len(df) == 1:\n","    df['BSF'] = df['Positive']/df['Negative']\n","  else:\n","    pos_mean = df['Positive'].mean()\n","    neg_mean = df['Negative'].mean()\n","    balance_sentiment = (abs(pos_mean - df['Positive'])+abs(neg_mean - df['Negative']))/2\n","    df['BSF'] = balance_sentiment \n","  return df\n","\n","# Microfactor 2\n","def get_SPR(df): # Standardized Party Ratio\n","  # Create a ratio to measure if text has a leniency towards a particular party\n","  party_ratio = df['Democrat']/df['Republican']\n","  # Standardized the ratio to make use of the overall mean and stand deviation\n","  if len(df) == 1:\n","    df['SPR'] = party_ratio\n","  else:\n","    df['SPR'] = abs(party_ratio - np.mean(party_ratio))/np.std(party_ratio)\n","  return df\n","\n","# Microfactor 3\n","def get_selection_bias(df, text_col=str): \n","  clean_col_name = 'Cleaned_'+text_col\n","  clean_text_token = df[text_col].apply(nltk.word_tokenize)\n","\n","  def count_bias_vocab(target, bias_list):\n","    count = 0 \n","    for vocab in bias_list:\n","      if vocab in target:\n","        count += 1\n","    return count/len(bias_list)\n","  \n","  file_id = '15DBBkgI0TVfciwwhDptWoblvhIHGKmq9'\n","  model_filename = 'vocab_selection.pkl'\n","  downloaded = gdrive.CreateFile({'id': file_id})\n","  downloaded.GetContentFile(model_filename)\n","  pickle_filepath = '/content/{}'.format(model_filename)\n","  vocab_selection = pickle.load(open(pickle_filepath, 'rb'))\n","\n","  lib_vocab_rate = clean_text_token.apply(count_bias_vocab,bias_list=vocab_selection['liberal'])\n","  con_vocab_rate = clean_text_token.apply(count_bias_vocab,bias_list=vocab_selection['conservative'])\n","  dem_vocab_rate = clean_text_token.apply(count_bias_vocab,bias_list=vocab_selection['democrat'])\n","  rep_vocab_rate = clean_text_token.apply(count_bias_vocab,bias_list=vocab_selection['republican'])\n","\n","  # Create two new feature\n","  # Weight more on liberal and conservative vocabs\n","  df['Dem_Vocab_Freq'] = 0.6*lib_vocab_rate+0.4*dem_vocab_rate\n","  df['Rep_Vocab_Freq'] = 0.6*con_vocab_rate+0.4*rep_vocab_rate\n","  # Create a selection bias feature\n","  df['Selection_Bias'] = df[[\"Dem_Vocab_Freq\", \"Rep_Vocab_Freq\"]].max(axis=1)\n","  return df\n","\n","# Combine all microfactors\n","def get_political_bias(df):\n","  # Microfactor final calculation\n","  if len(df) == 1:\n","    BSF_diff = df['BSF']\n","    SPR_diff = df['SPR']\n","  else:\n","    BSF_diff = abs(df['BSF'].mean() - df['BSF'])\n","    BSF_diff = (BSF_diff-min(BSF_diff))/(max(BSF_diff)-min(BSF_diff))\n","    SPR_diff = abs(df['SPR'].mean() - df['SPR'])\n","    SPR_diff = (SPR_diff-min(SPR_diff))/(max(SPR_diff)-min(SPR_diff))\n","  # Combine all the microfactors together\n","  political_bias = (0.2*BSF_diff+0.2*SPR_diff+0.2*(1-df['Neutral'])+0.4*df['Selection_Bias'])\n","  df['Political_Bias'] = political_bias\n","  return df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h046_6ZUkrtn"},"source":["To save time on loading zero shot model and create microfactors based on overall dataframe statistics, feature generation process (zero_shot_microfactors) is added in data prep notebook "]},{"cell_type":"code","metadata":{"id":"GWHV-rlDSBij"},"source":["def polit_bias_pipeline(df, clean_text_col=str):\n","  #df = zero_shot_microfactor(df, text_col) \n","  df = get_BSF(df)\n","  df = get_SPR(df)\n","  df = get_selection_bias(df, clean_text_col)\n","  df = get_political_bias(df)\n","  return df, df['Political_Bias']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fLx1PK9oogYU"},"source":["## 2.7. Title-Body Similarity Predictor"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2z5hxsa5oyNj","executionInfo":{"status":"ok","timestamp":1620488458739,"user_tz":420,"elapsed":60657,"user":{"displayName":"Yuxing Wang","photoUrl":"","userId":"03421613890437063978"}},"outputId":"0f3a5b00-6fb3-40ac-8fb6-d23f2ae19535"},"source":["!pip install nltk==3.4 --quiet\n","\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","from nltk.util import ngrams\n","from scipy.sparse import vstack\n","from scipy.spatial.distance import cosine\n","from sklearn import preprocessing\n","from sklearn.decomposition import TruncatedSVD\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","def cnt_sentences(df):\n","  df['cnt_title_sentences'] = df['clean_title'].apply(lambda x: len(sent_tokenize(x)))\n","  df['cnt_text_sentences'] = df['clean_body'].apply(lambda x: len(sent_tokenize(x)))\n","\n","def ngram(text, n):\n","    n_grams = ngrams(word_tokenize(text), n)\n","    return [ '_'.join(grams) for grams in n_grams]\n","\n","# Uni, Bi, Tri grams to get common word count features\n","def generate_ngrams(df):\n","  df[\"title_uni\"] = df[\"clean_title\"].map(lambda x: ngram(x, 1))\n","  df[\"body_uni\"] = df[\"clean_body\"].map(lambda x: ngram(x, 1))\n","  df[\"cnt_title_uni\"] = list(df.apply(lambda x: len(x['title_uni']), axis=1))\n","  df[\"cnt_body_uni\"] = list(df.apply(lambda x: len(x['body_uni']), axis=1))\n","  df[\"unq_cnt_title_uni\"] = list(df.apply(lambda x: len(set(x['title_uni'])), axis=1))\n","  df[\"unq_cnt_body_uni\"] = list(df.apply(lambda x: len(set(x['body_uni'])), axis=1))\n","\n","  df[\"title_bi\"] = df[\"clean_title\"].map(lambda x: ngram(x, 2))\n","  df[\"body_bi\"] = df[\"clean_body\"].map(lambda x: ngram(x, 2))\n","  df[\"cnt_title_bi\"] = list(df.apply(lambda x: len(x['title_bi']), axis=1))\n","  df[\"cnt_body_bi\"] = list(df.apply(lambda x: len(x['body_bi']), axis=1))\n","  df[\"unq_cnt_title_bi\"] = list(df.apply(lambda x: len(set(x['title_bi'])), axis=1))\n","  df[\"unq_cnt_body_bi\"] = list(df.apply(lambda x: len(set(x['body_bi'])), axis=1))\n","\n","  df[\"title_tri\"] = df[\"clean_title\"].map(lambda x: ngram(x, 3))\n","  df[\"body_tri\"] = df[\"clean_body\"].map(lambda x: ngram(x, 3))\n","  df[\"cnt_title_tri\"] = list(df.apply(lambda x: len(x['title_tri']), axis=1))\n","  df[\"cnt_body_tri\"] = list(df.apply(lambda x: len(x['body_tri']), axis=1))\n","  df[\"unq_cnt_title_tri\"] = list(df.apply(lambda x: len(set(x['title_tri'])), axis=1))\n","  df[\"unq_cnt_body_tri\"] = list(df.apply(lambda x: len(set(x['body_tri'])), axis=1))\n","\n","def common_ngrams_in_body(df):\n","  df[\"cnt_title_unis_in_body\"] =  list(df.apply(lambda x: sum([1. for w in x['title_uni'] if w in set(x['body_uni'])]), axis=1))\n","  df[\"cnt_title_bis_in_body\"] =  list(df.apply(lambda x: sum([1. for w in x['title_bi'] if w in set(x['body_bi'])]), axis=1))\n","  df[\"cnt_title_tris_in_body\"] =  list(df.apply(lambda x: sum([1. for w in x['title_tri'] if w in set(x['body_tri'])]), axis=1))\n","\n","def concat_title_body(df):\n","  df['clean_title_body'] = df['clean_title'] + ' ' + df['clean_body']\n","\n","def tf_idf(df):\n","  concat_title_body(df)\n","  combined_vectors = TfidfVectorizer(ngram_range=(1, 2), min_df=1, max_df=1, use_idf=True, smooth_idf=True)\n","  combined_vectors.fit(df[\"clean_title_body\"])\n","  combined_vectors_dictionary = combined_vectors.vocabulary_\n","  title_vectors = TfidfVectorizer(ngram_range=(1, 2), min_df=1, max_df=1, use_idf=True, smooth_idf=True, vocabulary=combined_vectors_dictionary)\n","  title_tfidf_vectors = title_vectors.fit_transform(df['clean_title'])\n","  text_vectors = TfidfVectorizer(ngram_range=(1, 2), min_df=1, max_df=1, use_idf=True, smooth_idf=True, vocabulary=combined_vectors_dictionary)\n","  text_tfidf_vectors = text_vectors.fit_transform(df['clean_body'])\n","  return title_tfidf_vectors, text_tfidf_vectors\n","\n","def similarity_score(df, title_vectors, text_vectors):\n","  similarity_score = []\n","  for i in range(len(df)):\n","      similarity_score.append(1 - cosine(title_vectors[i], text_vectors[i]))\n","  return similarity_score\n","\n","def tf_idf_similarity(df):\n","  title_tfidf_vectors, text_tfidf_vectors = tf_idf(df)\n","  df['similarity_title_body'] = similarity_score(df, title_tfidf_vectors.toarray(), text_tfidf_vectors.toarray())\n","  return title_tfidf_vectors, text_tfidf_vectors\n","\n","def svd(data, title_tfidf_vectors, text_tfidf_vectors):\n","  truncated_svd = TruncatedSVD(n_components=2, n_iter=10)\n","  combined_vectors = vstack([title_tfidf_vectors, text_tfidf_vectors])\n","  truncated_svd.fit(combined_vectors)\n","  title_svd = truncated_svd.transform(title_tfidf_vectors)\n","  text_svd = truncated_svd.transform(text_tfidf_vectors)\n","  return title_svd, text_svd\n","\n","def topic_similarity(data, title_tfidf_vectors, text_tfidf_vectors):\n","  title_svd_vectors, text_svd_vectors = svd(data, title_tfidf_vectors, text_tfidf_vectors)\n","  data['topics_similarity_title_body'] = similarity_score(data, title_svd_vectors, text_svd_vectors)\n","\n","def get_distilled_dataset(title, text):\n","  data = {'clean_title': [title.iloc[0]], 'clean_body': [text.iloc[0]]}\n","  df_test = pd.DataFrame(data)\n","  cnt_sentences(df_test)\n","  generate_ngrams(df_test)\n","  common_ngrams_in_body(df_test)\n","  title_tfidf_vectors, text_tfidf_vectors = tf_idf_similarity(df_test)\n","  topic_similarity(df_test, title_tfidf_vectors, text_tfidf_vectors)\n","  X_cols = [x for i,x in enumerate(features) if x!='label']\n","  return df_test[X_cols]\n","\n","features =     ['label',  'cnt_title_uni', 'cnt_body_uni',\n","                'unq_cnt_title_uni', 'unq_cnt_body_uni', 'cnt_title_bi', 'cnt_body_bi',\n","                'unq_cnt_title_bi', 'unq_cnt_body_bi', 'cnt_title_tri', 'cnt_body_tri',\n","                'unq_cnt_title_tri', 'unq_cnt_body_tri', 'cnt_title_unis_in_body', \n","                'cnt_title_bis_in_body', 'cnt_title_tris_in_body', 'similarity_title_body',\n","                'topics_similarity_title_body',\n","                ]\n","\n","le = preprocessing.LabelEncoder()\n","le.fit(['agree', 'disagree', 'discuss', 'unrelated'])\n","dict(zip(le.classes_, le.transform(le.classes_)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[?25l\r\u001b[K     |▎                               | 10kB 25.9MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 33.3MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 27.2MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 31.0MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51kB 28.1MB/s eta 0:00:01\r\u001b[K     |█▍                              | 61kB 30.8MB/s eta 0:00:01\r\u001b[K     |█▋                              | 71kB 19.9MB/s eta 0:00:01\r\u001b[K     |█▉                              | 81kB 20.9MB/s eta 0:00:01\r\u001b[K     |██                              | 92kB 19.3MB/s eta 0:00:01\r\u001b[K     |██▎                             | 102kB 19.4MB/s eta 0:00:01\r\u001b[K     |██▌                             | 112kB 19.4MB/s eta 0:00:01\r\u001b[K     |██▊                             | 122kB 19.4MB/s eta 0:00:01\r\u001b[K     |███                             | 133kB 19.4MB/s eta 0:00:01\r\u001b[K     |███▏                            | 143kB 19.4MB/s eta 0:00:01\r\u001b[K     |███▍                            | 153kB 19.4MB/s eta 0:00:01\r\u001b[K     |███▋                            | 163kB 19.4MB/s eta 0:00:01\r\u001b[K     |████                            | 174kB 19.4MB/s eta 0:00:01\r\u001b[K     |████▏                           | 184kB 19.4MB/s eta 0:00:01\r\u001b[K     |████▍                           | 194kB 19.4MB/s eta 0:00:01\r\u001b[K     |████▋                           | 204kB 19.4MB/s eta 0:00:01\r\u001b[K     |████▉                           | 215kB 19.4MB/s eta 0:00:01\r\u001b[K     |█████                           | 225kB 19.4MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 235kB 19.4MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 245kB 19.4MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 256kB 19.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 266kB 19.4MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 276kB 19.4MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 286kB 19.4MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 296kB 19.4MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 307kB 19.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 317kB 19.4MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 327kB 19.4MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 337kB 19.4MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 348kB 19.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 358kB 19.4MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 368kB 19.4MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 378kB 19.4MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 389kB 19.4MB/s eta 0:00:01\r\u001b[K     |█████████                       | 399kB 19.4MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 409kB 19.4MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 419kB 19.4MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 430kB 19.4MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 440kB 19.4MB/s eta 0:00:01\r\u001b[K     |██████████                      | 450kB 19.4MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 460kB 19.4MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 471kB 19.4MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 481kB 19.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 491kB 19.4MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 501kB 19.4MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 512kB 19.4MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 522kB 19.4MB/s eta 0:00:01\r\u001b[K     |████████████                    | 532kB 19.4MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 542kB 19.4MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 552kB 19.4MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 563kB 19.4MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 573kB 19.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 583kB 19.4MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 593kB 19.4MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 604kB 19.4MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 614kB 19.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 624kB 19.4MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 634kB 19.4MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 645kB 19.4MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 655kB 19.4MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 665kB 19.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 675kB 19.4MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 686kB 19.4MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 696kB 19.4MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 706kB 19.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 716kB 19.4MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 727kB 19.4MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 737kB 19.4MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 747kB 19.4MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 757kB 19.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 768kB 19.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 778kB 19.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 788kB 19.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 798kB 19.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 808kB 19.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 819kB 19.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 829kB 19.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 839kB 19.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 849kB 19.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 860kB 19.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 870kB 19.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 880kB 19.4MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 890kB 19.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 901kB 19.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 911kB 19.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 921kB 19.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 931kB 19.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 942kB 19.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 952kB 19.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 962kB 19.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 972kB 19.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 983kB 19.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 993kB 19.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.0MB 19.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.0MB 19.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.0MB 19.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.0MB 19.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.0MB 19.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.1MB 19.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.1MB 19.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1MB 19.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.1MB 19.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.1MB 19.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.1MB 19.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1MB 19.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.1MB 19.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.1MB 19.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.1MB 19.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.2MB 19.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2MB 19.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.2MB 19.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.2MB 19.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.2MB 19.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.2MB 19.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.2MB 19.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.2MB 19.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.2MB 19.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.2MB 19.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.3MB 19.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.3MB 19.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.3MB 19.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.3MB 19.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.3MB 19.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.3MB 19.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.3MB 19.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.3MB 19.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.3MB 19.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.4MB 19.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.4MB 19.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.4MB 19.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.4MB 19.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.4MB 19.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.4MB 19.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.4MB 19.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.4MB 19.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 19.4MB/s \n","\u001b[?25h  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'agree': 0, 'disagree': 1, 'discuss': 2, 'unrelated': 3}"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"WXwY8Kgm1V0Q"},"source":["def getTitleVsBodyPrediction(title, body):\n","  file_id = '1bwvFThCwg6pgM99R6p7Ly7K5vXPwRj6q'\n","  model_filename = 'title_body_similarity_model.pkl'\n","  downloaded = gdrive.CreateFile({'id': file_id})\n","  downloaded.GetContentFile(model_filename)\n","  pickle_filepath = '/content/{}'.format(model_filename)\n","  title_body_similarity_model = pickle.load(open(pickle_filepath, 'rb'))\n","  df_test = get_distilled_dataset(title, body)\n","  return title_body_similarity_model.predict(df_test), title_body_similarity_model.predict_proba(df_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SpAG3S6dvHc5"},"source":["## 2.8. Define a false-o-meter"]},{"cell_type":"code","metadata":{"id":"9Ufpr5uDd5sE"},"source":["# get false-o-meter reading of news item\n","def get_false_o_meter_reading(df, index_num, x_news=str, x_body=str):\n","    X_news = df[x_news]\n","    X_body = df[x_body]\n","    model_accuracy = [0.85, 0.73, 0.89, 0.92, 0.86, 0.97, 0.6, 0.7] \n","    model_weight = [acc/sum(model_accuracy) for acc in model_accuracy]\n","    probablity_false_news = []\n","\n","    # get sentiment reading\n","    sentiment_prob = getSentimentPrediction(X_news)\n","    probablity_false_news.append(model_weight[0] * sentiment_prob)\n","    print('Sentiment [false-o-meter] reading is %f ' %(sentiment_prob))\n","\n","    # get sensationalism reading\n","    sensationalism_prob = getSensationalismPrediction(X_news)\n","    probablity_false_news.append(model_weight[1] * sensationalism_prob)\n","    print('Sensationalism [false-o-meter] reading is %f ' %(sensationalism_prob))\n","\n","    # get distilled clickbait reading\n","    clickbait_prob = getDistilledClickBaitPrediction(X_news)\n","    probablity_false_news.append(model_weight[2] * clickbait_prob)\n","    print('Distilled Clickbait [false-o-meter] reading is %f ' %(clickbait_prob))\n","\n","    # get stance reading\n","    (agree_stance_prob, disagree_stance_prob, neutral_stance_prob) = getStancePrediction(X_news, X_body)\n","    probablity_false_news.append(model_weight[3] * agree_stance_prob) # agree stance\n","    probablity_false_news.append(model_weight[4] * disagree_stance_prob) # disagree stance\n","    probablity_false_news.append(model_weight[5] * neutral_stance_prob) # neutral stance\n","    print('Stance [false-o-meter] reading is (agree: %f, disagree: %f, neutral: %f)' % (agree_stance_prob, disagree_stance_prob, neutral_stance_prob))\n","\n","    # get political bias\n","    r = requests.get('https://docs.google.com/spreadsheets/d/e/2PACX-1vQd6WhaekUPRDxUIYXgx_zI_zAHodXl3__bfAnEa_GWT_eR9dVO55HALi_3jjnZmEwbZ_4YvUkG7Qtx/pub?gid=896471122&single=true&output=tsv')\n","    data = r.content\n","    zero_shot_microfactors = pd.read_csv(BytesIO(data), sep='\\t')\n","    pb_df, political_bias_prob = polit_bias_pipeline(zero_shot_microfactors, x_news)\n","    probablity_false_news.append(model_weight[6] * political_bias_prob.loc[index_num])\n","    print('Political Bias [false-o-meter] reading is %f ' %(political_bias_prob.loc[index_num]))\n","\n","    # get title body similarity\n","    title_body_pred, title_body_pred_prob = getTitleVsBodyPrediction(X_news, X_body)\n","    t_b_fake_score = (title_body_pred_prob[0][1] * 0.6 + title_body_pred_prob[0][3] + 0.4)\n","    probablity_false_news.append(model_weight[6] * t_b_fake_score)\n","    print('Title-Body incongruence [false-o-meter] reading is %f ' %(t_b_fake_score))\n","\n","    # get distilled psychology utility reading\n","    psychology_prob = getPsychologyUtilitiesPrediction(X_news)\n","    probablity_false_news.append(model_weight[2] * psychology_prob)\n","    print('Distilled Psychology Utility [false-o-meter] reading is %f ' %(psychology_prob))\n","  \n","    cummalative_probablity_false_news = sum(probablity_false_news)\n","    print('Ensembled [false-o-meter] reading is %f ' %(cummalative_probablity_false_news))\n","\n","    return cummalative_probablity_false_news"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jbMdc5tLoT7p"},"source":["##2.9. Define Psychology Predictor"]},{"cell_type":"code","metadata":{"id":"_A4Zueetoc7p"},"source":["import string\n","import joblib\n","\n","def get_text_processing(text):\n","  stop_words = stopwords.words('english')\n","  stop_words.append(['breaking', 'BREAKING'])\n","  no_punctuation = [char for char in text if char not in string.punctuation]\n","  no_punctuation = ''.join(no_punctuation)\n","  return ' '.join([word for word in no_punctuation.split() if word.lower() not in stop_words])\n","\n","def getPsychologyUtilitiesPrediction(X_news):\n","  prob = 0\n","  X_news = X_news.apply(get_text_processing)\n","  if X_news.size == 1:\n","    file_id = '16egOQ8zTftur5jPFxfWTwYDTOOjdhQ6e'\n","    model_filename = 'PsychologyUtilites_pipeline.pkl'\n","    downloaded = gdrive.CreateFile({'id': file_id})\n","    downloaded.GetContentFile(model_filename)\n","    pickle_filepath = '/content/{}'.format(model_filename)\n","    best_distilled_psychology_model = joblib.load(open(pickle_filepath, 'rb'))\n","    prob = best_distilled_psychology_model.predict(X_news)\n","  return 1 if prob == 'Positive' else 0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2EHyXA9Zd-CM"},"source":["# 3.0. Automated Inference Pipeline"]},{"cell_type":"markdown","metadata":{"id":"PnQh4rgCvSK4"},"source":["## 3.1. Helper: Pick a random news item"]},{"cell_type":"code","metadata":{"id":"sspSi0vxeQ04"},"source":["def get_random_news_items(num_items):\n","  random_news_items = df_test_headlines.sample(n=num_items)\n","  return random_news_items"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZJ8H3Y9ceDhM"},"source":["## 3.2. Helper:Print prediction of news item"]},{"cell_type":"code","metadata":{"id":"vXPuqpUyfGoN"},"source":["def print_prediction(reading):\n","  if reading > 0.9:\n","    print (\"This news headline is: Pants on Fire\")\n","  elif reading > 0.7 and reading < 0.9:\n","    print (\"This news headline is: Somewhat False\")\n","  elif reading > 0.5 and reading < 0.7:\n","    print (\"This news headline is: Mostly False\")\n","  elif reading > 0.3 and reading < 0.5:\n","    print (\"This news headline is: Half True\")\n","  elif reading > 0.1 and reading < 0.3:\n","    print (\"This news headline is: Mostly True\")\n","  elif reading < 0.1:\n","    print (\"True\")  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uqk1SUgEg_5k"},"source":["## 3.3. Helper: Run automated pipeline"]},{"cell_type":"code","metadata":{"id":"k1-VQtbUo69_"},"source":["def run_automated_inference_pipeline(num_items):\n","  X_headline = 'preprocessed_statement_text'\n","  X_body = 'preprocessed_body'\n","  random_news_items = get_random_news_items(num_items)\n","\n","  i = 0\n","  while ( i < num_items):\n","    news = random_news_items.sample(1)\n","    print('\\nRunning [false-o-meter] on - %s ' % (news['text']))\n","    reading = get_false_o_meter_reading(news, news.index[0], X_headline, X_body)\n","    print('[false-o-meter] reading is %f ' %(reading))\n","    print_prediction(reading)\n","    i = i + 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NRSFK3w0hUX7"},"source":["## 3.4. Invoke automated pipeline on 20 random news items"]},{"cell_type":"code","metadata":{"id":"elezXf39cBuv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620488772415,"user_tz":420,"elapsed":71001,"user":{"displayName":"Yuxing Wang","photoUrl":"","userId":"03421613890437063978"}},"outputId":"85427be4-e8e0-484f-ae4f-ef172371f9e3"},"source":["num_news = 20\n","reading = run_automated_inference_pipeline(num_news)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Running [false-o-meter] on - 185    Oscars 2021: Documentary Short Winner Acknowle...\n","Name: text, dtype: object \n","Sentiment [false-o-meter] reading is 0.483895 \n","Sensationalism [false-o-meter] reading is 0.315909 \n","Distilled Clickbait [false-o-meter] reading is 0.508695 \n","Stance [false-o-meter] reading is (agree: 0.964590, disagree: 0.035392, neutral: 0.000018)\n","Political Bias [false-o-meter] reading is 0.241166 \n","Title-Body incongruence [false-o-meter] reading is 0.406000 \n","Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n","Ensembled [false-o-meter] reading is 0.368227 \n","[false-o-meter] reading is 0.368227 \n","This news headline is: Half True\n","\n","Running [false-o-meter] on - 252    Chloe Zhao's Oscar win censored by Chinese soc...\n","Name: text, dtype: object \n","Sentiment [false-o-meter] reading is 0.499906 \n","Sensationalism [false-o-meter] reading is 0.315909 \n","Distilled Clickbait [false-o-meter] reading is 0.020867 \n","Stance [false-o-meter] reading is (agree: 0.999986, disagree: 0.000000, neutral: 0.000014)\n","Political Bias [false-o-meter] reading is 0.210396 \n","Title-Body incongruence [false-o-meter] reading is 0.424000 \n","Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n","Ensembled [false-o-meter] reading is 0.302875 \n","[false-o-meter] reading is 0.302875 \n","This news headline is: Half True\n","\n","Running [false-o-meter] on - 264    Asian man in critical condition after brutal a...\n","Name: text, dtype: object \n","Sentiment [false-o-meter] reading is 0.483895 \n","Sensationalism [false-o-meter] reading is 0.315909 \n","Distilled Clickbait [false-o-meter] reading is 0.132957 \n","Stance [false-o-meter] reading is (agree: 0.994726, disagree: 0.000001, neutral: 0.005274)\n","Political Bias [false-o-meter] reading is 0.255074 \n","Title-Body incongruence [false-o-meter] reading is 0.460000 \n","Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n","Ensembled [false-o-meter] reading is 0.323553 \n","[false-o-meter] reading is 0.323553 \n","This news headline is: Half True\n","\n","Running [false-o-meter] on - 42    Rolling Stones legend Ronnie Wood is cancer-fr...\n","Name: text, dtype: object \n","Sentiment [false-o-meter] reading is 0.502751 \n","Sensationalism [false-o-meter] reading is 0.315909 \n","Distilled Clickbait [false-o-meter] reading is 0.372800 \n","Stance [false-o-meter] reading is (agree: 0.999659, disagree: 0.000268, neutral: 0.000073)\n","Political Bias [false-o-meter] reading is 0.395866 \n","Title-Body incongruence [false-o-meter] reading is 0.410000 \n","Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n","Ensembled [false-o-meter] reading is 0.367063 \n","[false-o-meter] reading is 0.367063 \n","This news headline is: Half True\n","\n","Running [false-o-meter] on - 213    Oscars hit with largely negative reviews after...\n","Name: text, dtype: object \n","Sentiment [false-o-meter] reading is 0.483895 \n","Sensationalism [false-o-meter] reading is 0.315909 \n","Distilled Clickbait [false-o-meter] reading is 0.029016 \n","Stance [false-o-meter] reading is (agree: 0.983317, disagree: 0.000327, neutral: 0.016356)\n","Political Bias [false-o-meter] reading is 0.226702 \n","Title-Body incongruence [false-o-meter] reading is 0.454000 \n","Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n","Ensembled [false-o-meter] reading is 0.306283 \n","[false-o-meter] reading is 0.306283 \n","This news headline is: Half True\n","\n","Running [false-o-meter] on - 266    GOP AGs bring barrage of suits against Biden i...\n","Name: text, dtype: object \n","Sentiment [false-o-meter] reading is 0.483895 \n","Sensationalism [false-o-meter] reading is 0.503596 \n","Distilled Clickbait [false-o-meter] reading is 0.477105 \n","Stance [false-o-meter] reading is (agree: 0.996448, disagree: 0.001682, neutral: 0.001869)\n","Political Bias [false-o-meter] reading is 0.205240 \n","Title-Body incongruence [false-o-meter] reading is 0.506000 \n","Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n","Ensembled [false-o-meter] reading is 0.391150 \n","[false-o-meter] reading is 0.391150 \n","This news headline is: Half True\n","\n","Running [false-o-meter] on - 153    Poll: 80% Still Think U.S. Is ‘Mostly Divided,...\n","Name: text, dtype: object \n","Sentiment [false-o-meter] reading is 0.483895 \n","Sensationalism [false-o-meter] reading is 0.600400 \n","Distilled Clickbait [false-o-meter] reading is 0.478615 \n","Stance [false-o-meter] reading is (agree: 0.000632, disagree: 0.000000, neutral: 0.999368)\n","Political Bias [false-o-meter] reading is 0.212094 \n","Title-Body incongruence [false-o-meter] reading is 0.526000 \n","Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n","Ensembled [false-o-meter] reading is 0.412330 \n","[false-o-meter] reading is 0.412330 \n","This news headline is: Half True\n","\n","Running [false-o-meter] on - 228    Full of surprises: Royals own best AL record, ...\n","Name: text, dtype: object \n","Sentiment [false-o-meter] reading is 0.483895 \n","Sensationalism [false-o-meter] reading is 0.315909 \n","Distilled Clickbait [false-o-meter] reading is 0.654664 \n","Stance [false-o-meter] reading is (agree: 1.000000, disagree: 0.000000, neutral: 0.000000)\n","Political Bias [false-o-meter] reading is 0.306818 \n","Title-Body incongruence [false-o-meter] reading is 0.529000 \n","Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n","Ensembled [false-o-meter] reading is 0.405838 \n","[false-o-meter] reading is 0.405838 \n","This news headline is: Half True\n","\n","Running [false-o-meter] on - 264    Asian man in critical condition after brutal a...\n","Name: text, dtype: object \n","Sentiment [false-o-meter] reading is 0.483895 \n","Sensationalism [false-o-meter] reading is 0.315909 \n","Distilled Clickbait [false-o-meter] reading is 0.132957 \n","Stance [false-o-meter] reading is (agree: 0.994726, disagree: 0.000001, neutral: 0.005274)\n","Political Bias [false-o-meter] reading is 0.255074 \n","Title-Body incongruence [false-o-meter] reading is 0.460000 \n","Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n","Ensembled [false-o-meter] reading is 0.323553 \n","[false-o-meter] reading is 0.323553 \n","This news headline is: Half True\n","\n","Running [false-o-meter] on - 228    Full of surprises: Royals own best AL record, ...\n","Name: text, dtype: object \n","Sentiment [false-o-meter] reading is 0.483895 \n","Sensationalism [false-o-meter] reading is 0.315909 \n","Distilled Clickbait [false-o-meter] reading is 0.654664 \n","Stance [false-o-meter] reading is (agree: 1.000000, disagree: 0.000000, neutral: 0.000000)\n","Political Bias [false-o-meter] reading is 0.306818 \n","Title-Body incongruence [false-o-meter] reading is 0.529000 \n","Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n","Ensembled [false-o-meter] reading is 0.405838 \n","[false-o-meter] reading is 0.405838 \n","This news headline is: Half True\n","\n","Running [false-o-meter] on - 42    Rolling Stones legend Ronnie Wood is cancer-fr...\n","Name: text, dtype: object \n","Sentiment [false-o-meter] reading is 0.502751 \n","Sensationalism [false-o-meter] reading is 0.315909 \n","Distilled Clickbait [false-o-meter] reading is 0.372800 \n","Stance [false-o-meter] reading is (agree: 0.999659, disagree: 0.000268, neutral: 0.000073)\n","Political Bias [false-o-meter] reading is 0.395866 \n","Title-Body incongruence [false-o-meter] reading is 0.410000 \n","Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n","Ensembled [false-o-meter] reading is 0.367063 \n","[false-o-meter] reading is 0.367063 \n","This news headline is: Half True\n","\n","Running [false-o-meter] on - 213    Oscars hit with largely negative reviews after...\n","Name: text, dtype: object \n","Sentiment [false-o-meter] reading is 0.483895 \n","Sensationalism [false-o-meter] reading is 0.315909 \n","Distilled Clickbait [false-o-meter] reading is 0.029016 \n","Stance [false-o-meter] reading is (agree: 0.983317, disagree: 0.000327, neutral: 0.016356)\n","Political Bias [false-o-meter] reading is 0.226702 \n","Title-Body incongruence [false-o-meter] reading is 0.454000 \n","Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n","Ensembled [false-o-meter] reading is 0.306283 \n","[false-o-meter] reading is 0.306283 \n","This news headline is: Half True\n","\n","Running [false-o-meter] on - 107    Ukraine, Turkey Plan Joint Exercises in Black Sea\n","Name: text, dtype: object \n","Sentiment [false-o-meter] reading is 0.483895 \n","Sensationalism [false-o-meter] reading is 0.338104 \n","Distilled Clickbait [false-o-meter] reading is 0.044507 \n","Stance [false-o-meter] reading is (agree: 1.000000, disagree: 0.000000, neutral: 0.000000)\n","Political Bias [false-o-meter] reading is 0.259139 \n","Title-Body incongruence [false-o-meter] reading is 0.460000 \n","Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n","Ensembled [false-o-meter] reading is 0.314298 \n","[false-o-meter] reading is 0.314298 \n","This news headline is: Half True\n","\n","Running [false-o-meter] on - 185    Oscars 2021: Documentary Short Winner Acknowle...\n","Name: text, dtype: object \n","Sentiment [false-o-meter] reading is 0.483895 \n","Sensationalism [false-o-meter] reading is 0.315909 \n","Distilled Clickbait [false-o-meter] reading is 0.508695 \n","Stance [false-o-meter] reading is (agree: 0.964590, disagree: 0.035392, neutral: 0.000018)\n","Political Bias [false-o-meter] reading is 0.241166 \n","Title-Body incongruence [false-o-meter] reading is 0.406000 \n","Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n","Ensembled [false-o-meter] reading is 0.368227 \n","[false-o-meter] reading is 0.368227 \n","This news headline is: Half True\n","\n","Running [false-o-meter] on - 266    GOP AGs bring barrage of suits against Biden i...\n","Name: text, dtype: object \n","Sentiment [false-o-meter] reading is 0.483895 \n","Sensationalism [false-o-meter] reading is 0.503596 \n","Distilled Clickbait [false-o-meter] reading is 0.477105 \n","Stance [false-o-meter] reading is (agree: 0.996448, disagree: 0.001682, neutral: 0.001869)\n","Political Bias [false-o-meter] reading is 0.205240 \n","Title-Body incongruence [false-o-meter] reading is 0.506000 \n","Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n","Ensembled [false-o-meter] reading is 0.391150 \n","[false-o-meter] reading is 0.391150 \n","This news headline is: Half True\n","\n","Running [false-o-meter] on - 151    Man Purchases Google Argentina’s Domain Name f...\n","Name: text, dtype: object \n","Sentiment [false-o-meter] reading is 0.483895 \n","Sensationalism [false-o-meter] reading is 0.315909 \n","Distilled Clickbait [false-o-meter] reading is 0.460623 \n","Stance [false-o-meter] reading is (agree: 0.999382, disagree: 0.000602, neutral: 0.000016)\n","Political Bias [false-o-meter] reading is 0.279399 \n","Title-Body incongruence [false-o-meter] reading is 0.430000 \n","Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n","Ensembled [false-o-meter] reading is 0.367712 \n","[false-o-meter] reading is 0.367712 \n","This news headline is: Half True\n","\n","Running [false-o-meter] on - 69    Zendaya stuns Oscars red carpet in Cher-inspir...\n","Name: text, dtype: object \n","Sentiment [false-o-meter] reading is 0.483895 \n","Sensationalism [false-o-meter] reading is 0.315909 \n","Distilled Clickbait [false-o-meter] reading is 0.906297 \n","Stance [false-o-meter] reading is (agree: 0.296895, disagree: 0.000002, neutral: 0.703103)\n","Political Bias [false-o-meter] reading is 0.299992 \n","Title-Body incongruence [false-o-meter] reading is 0.478000 \n","Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n","Ensembled [false-o-meter] reading is 0.440257 \n","[false-o-meter] reading is 0.440257 \n","This news headline is: Half True\n","\n","Running [false-o-meter] on - 213    Oscars hit with largely negative reviews after...\n","Name: text, dtype: object \n","Sentiment [false-o-meter] reading is 0.483895 \n","Sensationalism [false-o-meter] reading is 0.315909 \n","Distilled Clickbait [false-o-meter] reading is 0.029016 \n","Stance [false-o-meter] reading is (agree: 0.983317, disagree: 0.000327, neutral: 0.016356)\n","Political Bias [false-o-meter] reading is 0.226702 \n","Title-Body incongruence [false-o-meter] reading is 0.454000 \n","Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n","Ensembled [false-o-meter] reading is 0.306283 \n","[false-o-meter] reading is 0.306283 \n","This news headline is: Half True\n","\n","Running [false-o-meter] on - 213    Oscars hit with largely negative reviews after...\n","Name: text, dtype: object \n","Sentiment [false-o-meter] reading is 0.483895 \n","Sensationalism [false-o-meter] reading is 0.315909 \n","Distilled Clickbait [false-o-meter] reading is 0.029016 \n","Stance [false-o-meter] reading is (agree: 0.983317, disagree: 0.000327, neutral: 0.016356)\n","Political Bias [false-o-meter] reading is 0.226702 \n","Title-Body incongruence [false-o-meter] reading is 0.454000 \n","Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n","Ensembled [false-o-meter] reading is 0.306283 \n","[false-o-meter] reading is 0.306283 \n","This news headline is: Half True\n","\n","Running [false-o-meter] on - 263    YouTube star Jake Paul rips UFC's Dana White: ...\n","Name: text, dtype: object \n","Sentiment [false-o-meter] reading is 0.483895 \n","Sensationalism [false-o-meter] reading is 0.315909 \n","Distilled Clickbait [false-o-meter] reading is 0.661233 \n","Stance [false-o-meter] reading is (agree: 0.925273, disagree: 0.074237, neutral: 0.000490)\n","Political Bias [false-o-meter] reading is 0.224411 \n","Title-Body incongruence [false-o-meter] reading is 0.512000 \n","Distilled Psychology Utility [false-o-meter] reading is 0.000000 \n","Ensembled [false-o-meter] reading is 0.396908 \n","[false-o-meter] reading is 0.396908 \n","This news headline is: Half True\n"],"name":"stdout"}]}]}